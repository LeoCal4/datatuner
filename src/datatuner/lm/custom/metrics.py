from typing import List, Tuple

import sacrebleu 
from rouge_metric import PyRouge
from moverscore_v2 import get_idf_dict, word_mover_score 
from collections import defaultdict


def group_inputs_and_outputs_by_data(model_inputs_and_outputs: List[Tuple[str]],
                                    datatuner_bleu_formatting: bool = False,
                                    pad_originals_length: bool = False) -> Tuple[List[List[str]], List[str]]:
    """Aggregate all the sentences which share the same original data.
    This is a slightly simplified data collection procedure of bleu(...) found in lm/metrics.py

    Args:
        inputs_and_outputs (List[Tuple[str]]): list of a zip containing both the model's inputs and outputs,
            specifically: input data, original sentence, generated beam of sentences 
        datatuner_bleu_formatting (bool)
        pad_originals_length (bool)

    Returns:
        Tuple(List[List[str]], List[str]): all the originals sentences and the predictions, grouped by data
    """
    grouped_items = {}
    max_num_of_og_sentences = 1
    for data, original_sentence, generated_sentences in model_inputs_and_outputs:
        generated_sentence = generated_sentences[0]
        #* lowercase sentences
        generated_sentence = generated_sentence.lower()
        original_sentence = original_sentence.lower()
        #* group the og and gen sentences by the values of their other keys (basically their data)
        if data in grouped_items:
            grouped_items[data]["original"].append(original_sentence)
            # this considerings just the last found sentence generated by certain data since the outputs doesn't change 
            grouped_items[data]["prediction"] = generated_sentence
            if len(grouped_items[data]["original"]) > max_num_of_og_sentences:
                max_num_of_og_sentences = len(grouped_items[data]["original"])
        else:
            grouped_items[data] = {"original": [original_sentence], "prediction": generated_sentence}
    if datatuner_bleu_formatting:
        all_predictions = []
        all_originals = [[] for _ in range(max_num_of_og_sentences)]
        for item in grouped_items.values():
            all_predictions.append(item["prediction"])
            for i in range(max_num_of_og_sentences):
                try:
                    all_originals[i].append(item["original"][i])
                except:
                    all_originals[i].append("")
    else:
        for item in grouped_items.values():
            all_predictions.append(item["prediction"])
            if pad_originals_length and len(item["original"]) < max_num_of_og_sentences:
                item["original"].extend(["" for _ in range(max_num_of_og_sentences - len(item["original"]))])
            all_originals.append(item["original"])
    return all_originals, all_predictions


def corpus_level_bleu(model_inputs_and_outputs: List[Tuple[str]]):
    """

    Args:
        inputs_and_outputs (List[List[str]]): list of a zip containing both the model's inputs and outputs,
            specifically: input data, original sentence, generated beam of sentences 

    Returns:
        Dict[str, float]: dict containing the corpus-level bleu and the number of sentences taken into account 
    """
    all_originals, all_predictions = group_inputs_and_outputs_by_data(model_inputs_and_outputs, datatuner_bleu_formatting=True)
    return sacrebleu.corpus_bleu(all_predictions, all_originals).score


def corpus_level_meteor(model_inputs_and_outputs: List[Tuple[str]]) -> float:
    pass


def corpus_level_rogue(model_inputs_and_outputs: List[Tuple[str]]) -> float:
    all_originals, all_predictions = group_inputs_and_outputs_by_data(model_inputs_and_outputs)
    rouge = PyRouge(rouge_n=False, rouge_l=True)
    scores = rouge.evaluate(all_predictions, all_originals)
    return scores["rouge-l"]


def corpus_level_mover_score(model_inputs_and_outputs: List[Tuple[str]]) -> float:
    all_originals, all_predictions = group_inputs_and_outputs_by_data(model_inputs_and_outputs)
    idf_dict_pred = get_idf_dict(all_predictions) # idf_dict_hyp = defaultdict(lambda: 1.)
    idf_dict_og = get_idf_dict(all_originals) # idf_dict_ref = defaultdict(lambda: 1.)
    scores = word_mover_score(all_originals, all_predictions, idf_dict_og, idf_dict_pred, \
                            stop_words=[], n_gram=1, remove_subwords=True)
    return scores
    
